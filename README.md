# ScraptGPT
## AI-Powered Live Chat & Web Search Platform
Full-stack, streaming-enabled conversational AI platform combining a Next.js (TypeScript) frontend with a FastAPI backend, integrated with LangChain, LangGraph, and OpenAI APIs for real-time, contextual web search and AI chat.


ğŸš€ Features
ğŸ”´ Real-Time Token Streaming â€” Frontend & backend streaming pipeline for low-latency conversational updates (~60â€“80% faster perceived response).

ğŸ§  Multi-Agent Reasoning â€” LangGraph DAG orchestration + LangChain agents for live web search, parsing, summarization, and contextual answers.

ğŸ’¬ Dynamic & Context-Aware Responses â€” Integrated with OpenAI LLMs, ReACT-style prompt engineering, and API connectors (weather, search, etc.).

ğŸ–¥ï¸ Adaptive UI â€” Markdown-supported chat interface, mobile responsive, with secure CORS-based API communication.

ğŸ“Š Observability & Debugging Tools â€” Token usage tracking, reasoning path visualization, and latency metrics logging.

ğŸ—ï¸ Tech Stack
Frontend:

Next.js (TypeScript)

Tailwind CSS

Markdown Rendering (react-markdown)

Backend:

FastAPI (Python)

LangChain, LangGraph

Async API Streaming

OpenAI API

Deployment & DevOps:

Vercel (Frontend)

Environment-based secrets management

Cross-Origin Resource Sharing (CORS)

ğŸ“‚ Project Structure
bash
Copy
Edit
â”œâ”€â”€ client/                 # Next.js frontend
â”‚   â”œâ”€â”€ components/         # UI components
â”‚   â”œâ”€â”€ pages/              # Routes
â”‚   â””â”€â”€ styles/             # Tailwind CSS
â”œâ”€â”€ server/                 # FastAPI backend
â”‚   â”œâ”€â”€ agents/             # LangChain/LangGraph logic
â”‚   â”œâ”€â”€ routes/             # API endpoints
â”‚   â””â”€â”€ utils/              # Helper functions
â””â”€â”€ README.md               # Project documentation


## âš¡ Getting Started
1ï¸âƒ£ Clone the Repository
bash
Copy
Edit
git clone https://github.com/<your-username>/<repo-name>.git
cd <repo-name>
2ï¸âƒ£ Install Dependencies
Frontend:

bash
Copy
Edit
cd client
npm install
Backend:

bash
Copy
Edit
cd server
pip install -r requirements.txt
3ï¸âƒ£ Set Environment Variables
Create .env files in both client and server with:

ini
Copy
Edit
OPENAI_API_KEY=your_openai_api_key
CORS_ORIGINS=http://localhost:3000
4ï¸âƒ£ Run the App
Frontend:

bash
Copy
Edit
npm run dev
Backend:

bash
Copy
Edit
uvicorn main:app --reload
ğŸ“ˆ Performance
Streaming Pipeline â€” Reduced perceived latency by ~60â€“80%

Agent Orchestration â€” Modular reasoning steps using LangGraph DAG

Scalable Deployment â€” Vercel + environment-based secrets for secure and quick deploys

ğŸ› ï¸ Future Enhancements
ğŸ” Multi-source knowledge retrieval (PDFs, databases, APIs)

ğŸ—£ï¸ Voice-based interaction support

ğŸ“Š Analytics dashboard for chat performance and search insights

ğŸ“œ License
MIT License â€” Free to use and modify.
